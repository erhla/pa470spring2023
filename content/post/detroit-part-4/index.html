---
title: "Detroit Part 4"
date: 2023-03-30
categories: ["R"]
tags: ["detroit"]
publishdate: 2023-03-23
---



<div id="assignment" class="section level2">
<h2>Assignment</h2>
<p>Instead of traditional problem sets, this course has a single four part assignment where you will build upon your previous work each week with new material from the course. You will explore property assessment in Detroit, Michigan and create an assessment model. After the completion of the assignment, you will wrap your model into a report which analyzes the effectiveness of your model based on the ethical and other frameworks from class and make a brief presentation to the class.</p>
</div>
<div id="submissions" class="section level2">
<h2>Submissions</h2>
<p>Each week you will submit two files on blackboard, your code/Rmd file and the knitted output of your code. Blackboard will not accept html files so you must zip the files together.</p>
</div>
<div id="final-submission-due-331" class="section level2">
<h2>Final Submission (Due 3/31)</h2>
<p>Create <code>final_report.Rmd</code> in the reports folder, copying the yaml/framework from <code>part_1.Rmd</code>.</p>
<p>Bring together your previous submissions into one cohesive report. This report should offer a brief overview of the problem (assessment), general trends on properties, your model, why your model is better than other models, and any technical or ethical critiques.</p>
<p>Your final submission will build upon your part 3 submission by ‘switching out’ the model you use and adding a conclusion.</p>
<div id="part-a-new-assessment-models" class="section level3">
<h3>Part A, New Assessment Models</h3>
<p>Mirror Section 15.3 from the textbook for your assessment model only!</p>
<ul>
<li>Create a <code>workflow_set()</code> of three different model types. You may choose any which are comparable with <code>tidymodels</code>. Suggested models and tuning parameters below. I <strong>encourage</strong> you to consider using one model not from this list, but that is optional.</li>
</ul>
<pre><code>linear_reg_spec &lt;- 
  linear_reg(penalty = tune(), mixture = tune()) %&gt;% 
  set_engine(&quot;glmnet&quot;)

rf_spec &lt;- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 250) %&gt;% 
  set_engine(&quot;ranger&quot;) %&gt;% 
  set_mode(&quot;regression&quot;)

xgb_spec &lt;- 
  boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
             min_n = tune(), sample_size = tune(), trees = tune()) %&gt;% 
  set_engine(&quot;xgboost&quot;) %&gt;% 
  set_mode(&quot;regression&quot;)

my_set &lt;- workflow_set(
  preproc = list(name_for_your_recipie = your_recipie),
  models = list(linear_reg = linear_reg_spec, random_forest = rf_spec, boosted = xgb_spec)
)</code></pre>
<p>The textbook applies slightly different preprocessing steps to these models, but they should work reasonably well with your current recipe. If you have any compatability issues, I recommend starting with a simple recipe and adding things back one at a time.</p>
<ul>
<li>Now, apply <code>workflow_map()</code> to your <code>workflow_set()</code>. You should resample your testing data and create a small grid. Please use at least 3 resamples and a grid of at least 5. This may take a long time (10+ minutes). I recommend starting very small and gradually increasing your resamples/grid. Note that I’ve included verbose = TRUE here to help you debug, please do not include this output in your final project.</li>
</ul>
<pre><code>grid_ctrl &lt;-
   control_grid(
      save_pred = FALSE,
      save_workflow = FALSE
   )

grid_results &lt;-
   my_set %&gt;%
   workflow_map(
      seed = 1503,
      resamples = your_resamples,
      grid = 5,
      control = grid_ctrl,
      verbose = TRUE
   )
   </code></pre>
<ul>
<li>Now, use <code>rank_results</code> on your selected performance metric and <code>autoplot</code> to replicate figure 15.1. Does one model perform significantly better than others? Select what you feel is the best by finalizing your model (see Section 15.5).</li>
</ul>
<pre><code>best_results &lt;- 
   grid_results %&gt;% 
   extract_workflow_set_result(&quot;best model type name&quot;) %&gt;% 
   select_best(metric = &quot;your metric&quot;)
best_results

best_results_fit &lt;- 
   grid_results %&gt;% 
   extract_workflow(&quot;best model type name&quot;) %&gt;% 
   finalize_workflow(best_results) %&gt;% 
   last_fit(split = your_rsample_data) #this is the output of rsample::initial_time_split() or rsample::initial_split()</code></pre>
<ul>
<li>Consider making a simple visualization of predicted / observed values from your best model similar to Figure 15.5</li>
</ul>
<pre><code>best_results_fit %&gt;% 
   collect_predictions() %&gt;% 
   ggplot(aes(x = target_variable, y = .pred)) + 
   geom_abline(color = &quot;gray50&quot;, lty = 2) + 
   geom_point(alpha = 0.5) + 
   coord_obs_pred() + 
   labs(x = &quot;observed&quot;, y = &quot;predicted&quot;)</code></pre>
</div>
<div id="part-b-hyperparameter-exploration-for-classification" class="section level3">
<h3>Part B, Hyperparameter Exploration for Classification</h3>
<p>Mirroring Section 14.2.3, take your current workflow and use <code>tune_bayes()</code> to create a small tuning grid for your classification model. You will need to:</p>
<ul>
<li>Identify appropriate hyperparameters to be tuned for your chosen model type and set them equal to <code>tune()</code> in your workflow (note: do not include <code>mtry</code> in your tuning grid)</li>
<li>Manually create a start_grid and evaluate your workflow to create initial values for <code>tune_bayes()</code></li>
</ul>
<pre><code>initial_vals &lt;- your_workflow %&gt;%
  tune_grid(
    resampled_data,
    grid = 4,
    metrics = your_metric_set,
  )</code></pre>
<ul>
<li>Run a bayes search</li>
</ul>
<pre><code>ctrl &lt;- control_bayes(verbose = TRUE)

your_search &lt;- 
  your_workflow %&gt;%
  tune_bayes(
    resamples = ...,
    metrics = ...,
    initial = initial_vals, #note you may simply pass a number here e.g. 6 for a random search
    iter = 25,
    control = ctrl
  )</code></pre>
<ul>
<li>Call <code>show_best</code> and finalize your model</li>
</ul>
</div>
<div id="part-c-conclusion-presentation" class="section level3">
<h3>Part C, Conclusion &amp; Presentation</h3>
<p>Write a four paragraph conclusion to your file. Include information on your model type, its performance on your chosen objective function, any ethical or implementation issues (e.g. should Detroit use your model?).</p>
<p>In class on the 31st, everyone will give a brief presentation on their work. You may present your knitted Rmd file or pull some of your graphs into a slide deck. Your presentation should be at most five minutes. Broadly look to answer if your model should be implemented by discussing the information in your conclusion and assignment.</p>
</div>
</div>
<div id="grading-overview" class="section level2">
<h2>Grading Overview</h2>
<p>For each assignment, you will be graded on substantial completion of the assignment (demonstrated by an attempt of all parts). When submitting parts 2, 3, and 4, you will be additionally graded on your incorporation of feedback, new concepts from the course, or the correction of any flagged issues.</p>
<p>The assignment will culminate in a final submission of code/report and presentation. Code will be graded based on reproducibility, conceptual understanding, and accuracy. The report will be an Rmarkdown file which knits together graphs, tables, and ethical frameworks. It should be concise (include only relevant information from Parts 1-4). This report will be used to give a five minute presentation to the class on your model and ethical/technical issues with Detroit property assessment.</p>
<table>
<colgroup>
<col width="9%" />
<col width="9%" />
<col width="41%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th>Date</th>
<th>Points</th>
<th>Category</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>13-Feb</td>
<td>5</td>
<td>Substantial Completion (attempted all parts)</td>
<td>Part 1 Due</td>
</tr>
<tr class="even">
<td>23-Feb</td>
<td>5</td>
<td>Substantial Completion (attempted all parts)</td>
<td>Part 2 Due</td>
</tr>
<tr class="odd">
<td>23-Feb</td>
<td>5</td>
<td>Incorporation of Feedback/New Concepts</td>
<td>From Part 1</td>
</tr>
<tr class="even">
<td>16-Mar</td>
<td>10</td>
<td>Substantial Completion (attempted all parts)</td>
<td>Part 3 Due</td>
</tr>
<tr class="odd">
<td>16-Mar</td>
<td>10</td>
<td>Incorporation of Feedback/New Concepts</td>
<td>From Part 2</td>
</tr>
<tr class="even">
<td>30-Mar</td>
<td>30</td>
<td>Final Code</td>
<td>Reproducible (10), Concepts (10), Accurate (10)</td>
</tr>
<tr class="odd">
<td>30-Mar</td>
<td>20</td>
<td>Final Report</td>
<td>Via Rmarkdown HTML, contextualized analysis and ethics</td>
</tr>
<tr class="even">
<td>30-Mar</td>
<td>15</td>
<td>Final Presentation</td>
<td>3-5 minute presentation on model and insights</td>
</tr>
</tbody>
</table>
</div>
